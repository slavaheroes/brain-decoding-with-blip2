{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corticalsulc.nii.gz\tlh.Kastner2015.nii.gz\t  rh.floc-faces.nii.gz\r\n",
      "floc-bodies.nii.gz\tlh.MTL.nii.gz\t\t  rh.floc-places.nii.gz\r\n",
      "floc-faces.nii.gz\tlh.nsdgeneral.nii.gz\t  rh.floc-words.nii.gz\r\n",
      "floc-places.nii.gz\tlh.prf-eccrois.nii.gz\t  rh.HCP_MMP1.nii.gz\r\n",
      "floc-words.nii.gz\tlh.prf-visualrois.nii.gz  rh.Kastner2015.nii.gz\r\n",
      "HCP_MMP1.nii.gz\t\tlh.streams.nii.gz\t  rh.MTL.nii.gz\r\n",
      "Kastner2015.nii.gz\tlh.thalamus.nii.gz\t  rh.nsdgeneral.nii.gz\r\n",
      "lh.corticalsulc.nii.gz\tMTL.nii.gz\t\t  rh.prf-eccrois.nii.gz\r\n",
      "lh.floc-bodies.nii.gz\tnsdgeneral.nii.gz\t  rh.prf-visualrois.nii.gz\r\n",
      "lh.floc-faces.nii.gz\tprf-eccrois.nii.gz\t  rh.streams.nii.gz\r\n",
      "lh.floc-places.nii.gz\tprf-visualrois.nii.gz\t  rh.thalamus.nii.gz\r\n",
      "lh.floc-words.nii.gz\trh.corticalsulc.nii.gz\t  streams.nii.gz\r\n",
      "lh.HCP_MMP1.nii.gz\trh.floc-bodies.nii.gz\t  thalamus.nii.gz\r\n"
     ]
    }
   ],
   "source": [
    "! ls /SSD/slava/brain_decoding/nsd/data/nsddata/ppdata/subj01/func1pt8mm/roi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io as spio\n",
    "import nibabel as nib\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle \n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "    \n",
    "def save_pickle(data, path):\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "    \n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    def _check_keys(d):\n",
    "        '''\n",
    "        checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        '''\n",
    "        for key in d:\n",
    "            if isinstance(d[key], spio.matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        '''\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        '''\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _tolist(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _tolist(ndarray):\n",
    "        '''\n",
    "        A recursive function which constructs lists from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        '''\n",
    "        elem_list = []\n",
    "        for sub_elem in ndarray:\n",
    "            if isinstance(sub_elem, spio.matlab.mio5_params.mat_struct):\n",
    "                elem_list.append(_todict(sub_elem))\n",
    "            elif isinstance(sub_elem, np.ndarray):\n",
    "                elem_list.append(_tolist(sub_elem))\n",
    "            else:\n",
    "                elem_list.append(sub_elem)\n",
    "        return elem_list\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating mean:   5%|████▎                                                                          | 2/37 [00:21<06:14, 10.71s/it]"
     ]
    }
   ],
   "source": [
    "for subj in [1, 2, 5, 7]:\n",
    "    train_fmri = load_pickle(f'/SSD/slava/THESIS/NSD_processed/subj{subj}_train_mri_to_nsd-img.pkl')\n",
    "    test_fmri = load_pickle(f'/SSD/slava/THESIS/NSD_processed/subj{subj}_test_mri_to_nsd-img.pkl')\n",
    "\n",
    "    betas_dir = '/SSD/slava/brain_decoding/nsd/data/nsddata_betas/ppdata/subj{:02d}/func1pt8mm/betas_fithrf_GLMdenoise_RR/'.format(subj)\n",
    "    roi_dir = '/SSD/slava/brain_decoding/nsd/data/nsddata/ppdata/subj{:02d}/func1pt8mm/roi/'.format(subj)\n",
    "    \n",
    "    # depending on the subj\n",
    "    if subj==1:\n",
    "        shape = (1, 81, 104, 83)\n",
    "    elif subj==2:\n",
    "        shape = (1, 82, 106, 84)\n",
    "    elif subj==5:\n",
    "        shape = (1, 79, 97, 78)\n",
    "    elif subj==7:\n",
    "        shape = (1, 78, 95, 81)\n",
    "    else:\n",
    "        raise ValueError('Wrong subject')\n",
    "\n",
    "    mean_arr = np.zeros(shape) \n",
    "\n",
    "    for i in tqdm(range(37), desc=\"Calculating mean\"):\n",
    "        beta_filename = \"betas_session{0:02d}.nii.gz\".format(i+1)\n",
    "        beta_f = nib.load(betas_dir+beta_filename).get_fdata().astype(np.float32)\n",
    "\n",
    "        beta_f_transposed = np.transpose(beta_f, axes=(3, 0, 1, 2))\n",
    "        for j in range(beta_f_transposed.shape[0]):\n",
    "            fmriId = (i*750) + j\n",
    "            if fmriId in train_fmri:\n",
    "                mean_arr += beta_f_transposed[j, :, :, :]/300\n",
    "\n",
    "        del beta_f, beta_f_transposed\n",
    "\n",
    "    mean_arr = mean_arr/len(train_fmri)\n",
    "    print(\"Mean is calculated for Subject \", subj)\n",
    "    \n",
    "    print(\"Mean unique values: \", np.unique(mean_arr))\n",
    "    \n",
    "    std_arr = np.zeros(shape)\n",
    "    ddof = 1\n",
    "\n",
    "    for i in tqdm(range(37), desc=\"Calculating std\"):\n",
    "        beta_filename = \"betas_session{0:02d}.nii.gz\".format(i+1)\n",
    "        beta_f = nib.load(betas_dir+beta_filename).get_fdata().astype(np.float32)\n",
    "\n",
    "        beta_f_transposed = np.transpose(beta_f, axes=(3, 0, 1, 2))\n",
    "\n",
    "        for j in range(beta_f_transposed.shape[0]):\n",
    "            fmriId = (i*750) + j\n",
    "            if fmriId in train_fmri:\n",
    "                std_arr += np.abs((beta_f_transposed[j, :, :, :]/300) - mean_arr) ** 2\n",
    "\n",
    "        del beta_f, beta_f_transposed\n",
    "\n",
    "    std_arr = np.sqrt(std_arr/(len(train_fmri) - ddof))\n",
    "    \n",
    "    print(\"Std is calculated for Subject \", subj)\n",
    "    print(\"Std unique values: \", np.unique(std_arr))\n",
    "    \n",
    "    print('Saving mean and std')\n",
    "    # save these stats\n",
    "    np.save(\"/SSD/slava/THESIS/NSD_processed/subj{:02d}/train_mean.npy\".format(subj),\n",
    "           mean_arr)\n",
    "\n",
    "    np.save(\"/SSD/slava/THESIS/NSD_processed/subj{:02d}/train_std.npy\".format(subj),\n",
    "           std_arr)\n",
    "    \n",
    "    \n",
    "    save_dir = \"/SSD/slava/THESIS/NSD_processed/subj{:02d}/fMRI_frames_normalized\".format(subj)\n",
    "\n",
    "    for i in tqdm(range(37), desc=\"Saving fMRI\"):\n",
    "        beta_filename = \"betas_session{0:02d}.nii.gz\".format(i+1)\n",
    "        beta_f = nib.load(betas_dir+beta_filename).get_fdata().astype(np.float32)\n",
    "\n",
    "        beta_f_transposed = np.transpose(beta_f, axes=(3, 0, 1, 2))\n",
    "\n",
    "        for j in range(beta_f_transposed.shape[0]):\n",
    "            fmriId = (i*750) + j\n",
    "            normalized = (beta_f_transposed[j, :, :, :]/300 - mean_arr) / (std_arr + 1e-6)\n",
    "\n",
    "            if fmriId in train_fmri:\n",
    "                split = 'train'\n",
    "            elif fmriId in test_fmri:\n",
    "                split = 'test'\n",
    "\n",
    "            np.save(\n",
    "                   os.path.join(save_dir, f'fmri_{fmriId}_{split}.npy'),\n",
    "                   normalized\n",
    "            )\n",
    "            \n",
    "    \n",
    "    print('Copying ROIs')\n",
    "    # copy rois\n",
    "    copy_tree(roi_dir,\n",
    "             \"/SSD/slava/THESIS/NSD_processed/subj{:02d}/roi\".format(subj))\n",
    "    \n",
    "    print(\"Done for subj \", subj)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number with assert\n",
    "for subj in [1, 2, 5, 7]:\n",
    "    train_fmri = load_pickle(f'/SSD/slava/THESIS/NSD_processed/subj{subj}_train_mri_to_nsd-img.pkl')\n",
    "    test_fmri = load_pickle(f'/SSD/slava/THESIS/NSD_processed/subj{subj}_test_mri_to_nsd-img.pkl')\n",
    "\n",
    "    train_files = glob(f'/SSD/slava/THESIS/NSD_processed/subj0{subj}/fMRI_frames_normalized/*_train.npy')\n",
    "    test_files = glob(f'/SSD/slava/THESIS/NSD_processed/subj0{subj}/fMRI_frames_normalized/*_test.npy')\n",
    "    \n",
    "    assert len(train_files)==len(train_fmri)\n",
    "    assert len(test_files)==len(test_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
